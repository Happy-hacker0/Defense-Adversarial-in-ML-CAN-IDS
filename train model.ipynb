{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv1D,MaxPool1D\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "from joblib import dump, load\n",
    "import queue\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os, sys\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9698636262016543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97     22799\n",
      "           1       0.97      0.97      0.97     21931\n",
      "\n",
      "    accuracy                           0.97     44730\n",
      "   macro avg       0.97      0.97      0.97     44730\n",
      "weighted avg       0.97      0.97      0.97     44730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./Dataset/csv/Attack_merge.csv', newline='') as csvfile:\n",
    "        rows = pd.read_csv(csvfile,header=None)\n",
    "        y = rows[10]\n",
    "        x = rows.drop([10], axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y , test_size=0.2)\n",
    "    \n",
    "if not os.path.exists(\"./models\"):\n",
    "    os.mkdir(\"./models\")\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/DT.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948647440196736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     22799\n",
      "           1       0.99      0.91      0.95     21931\n",
      "\n",
      "    accuracy                           0.95     44730\n",
      "   macro avg       0.95      0.95      0.95     44730\n",
      "weighted avg       0.95      0.95      0.95     44730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=20, max_depth=4)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/RF.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9075788061703555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91     22799\n",
      "           1       0.90      0.91      0.91     21931\n",
      "\n",
      "    accuracy                           0.91     44730\n",
      "   macro avg       0.91      0.91      0.91     44730\n",
      "weighted avg       0.91      0.91      0.91     44730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=3)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/LR.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:10] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9765034652358596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98     22799\n",
      "           1       0.97      0.98      0.98     21931\n",
      "\n",
      "    accuracy                           0.98     44730\n",
      "   macro avg       0.98      0.98      0.98     44730\n",
      "weighted avg       0.98      0.98      0.98     44730\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(booster=\"gbtree\", min_split_loss=7.100747859845302e-07, alpha=0.0010277375135306342, \n",
    "                        max_depth=9, eta=0.6737504946980999, gamma=6.101266632438708e-07, grow_policy=\"lossguide\")\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/XGB.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9097250167672702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91     22799\n",
      "           1       0.91      0.91      0.91     21931\n",
      "\n",
      "    accuracy                           0.91     44730\n",
      "   macro avg       0.91      0.91      0.91     44730\n",
      "weighted avg       0.91      0.91      0.91     44730\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C = 2, verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/SVM.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9751844399731724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98     22799\n",
      "           1       0.97      0.98      0.97     21931\n",
      "\n",
      "    accuracy                           0.98     44730\n",
      "   macro avg       0.98      0.98      0.98     44730\n",
      "weighted avg       0.98      0.98      0.98     44730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/KNN.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/10\n",
      "4194/4194 [==============================] - 30s 7ms/step - loss: 0.2397 - accuracy: 0.8847 - val_loss: 0.1943 - val_accuracy: 0.8980\n",
      "Epoch 2/10\n",
      "4194/4194 [==============================] - 27s 6ms/step - loss: 0.1881 - accuracy: 0.9141 - val_loss: 0.2107 - val_accuracy: 0.8960\n",
      "Epoch 3/10\n",
      "4194/4194 [==============================] - 29s 7ms/step - loss: 0.1814 - accuracy: 0.9173 - val_loss: 0.1757 - val_accuracy: 0.9221\n",
      "Epoch 4/10\n",
      "4194/4194 [==============================] - 29s 7ms/step - loss: 0.2010 - accuracy: 0.9113 - val_loss: 0.1880 - val_accuracy: 0.8985\n",
      "Epoch 5/10\n",
      "4194/4194 [==============================] - 29s 7ms/step - loss: 0.1934 - accuracy: 0.9125 - val_loss: 0.1772 - val_accuracy: 0.9241\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/10\n",
      "4194/4194 [==============================] - 28s 7ms/step - loss: 0.1846 - accuracy: 0.9168 - val_loss: 0.1591 - val_accuracy: 0.9275\n",
      "Epoch 7/10\n",
      "4194/4194 [==============================] - 30s 7ms/step - loss: 0.1754 - accuracy: 0.9201 - val_loss: 0.1548 - val_accuracy: 0.9294\n",
      "Epoch 8/10\n",
      "4194/4194 [==============================] - 31s 7ms/step - loss: 0.1709 - accuracy: 0.9219 - val_loss: 0.1533 - val_accuracy: 0.9294\n",
      "Epoch 9/10\n",
      "4194/4194 [==============================] - 29s 7ms/step - loss: 0.1716 - accuracy: 0.9205 - val_loss: 0.1552 - val_accuracy: 0.9291\n",
      "Epoch 10/10\n",
      "4194/4194 [==============================] - 29s 7ms/step - loss: 0.1709 - accuracy: 0.9211 - val_loss: 0.1540 - val_accuracy: 0.9294\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('./models/DNN4_Best_Model.h5', save_weights_only=False, save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, epsilon=1e-4, mode='min')\n",
    "\n",
    "dnn4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(8, activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(4, activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "dnn4.compile(optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']);\n",
    "\n",
    "dnn4.fit(X_train, y_train, batch_size=batch_size, epochs=10, verbose=1, callbacks=[earlyStopping, mcp_save, reduce_lr_loss], validation_split=0.25)\n",
    "model = tf.keras.models.load_model('./models/DNN4_Best_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9312541918175721\n",
      "f1: 0.9284767287697998\n",
      "prec: 0.94763080429209\n",
      "recall: 0.9100816196251881\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "pred_labels = np.rint(preds)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test, pred_labels[0:,1])\n",
    "f1 = sklearn.metrics.f1_score(y_test, pred_labels[0:,1], average=\"binary\")\n",
    "prec = sklearn.metrics.precision_score(y_test, pred_labels[0:,1], average=\"binary\")\n",
    "recall = sklearn.metrics.recall_score(y_test, pred_labels[0:,1], average=\"binary\")\n",
    "print(\"accuracy: \" + str(accuracy))\n",
    "print(\"f1: \" + str(f1))\n",
    "print(\"prec: \" + str(prec))\n",
    "print(\"recall: \" + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./models/DNN4_Best_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Conv1D, MaxPooling1D, Embedding, GlobalAveragePooling1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=100, kernel_size=10, activation='relu',strides=5, input_shape=(sequence_length, num_features)))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(filters=200, kernel_size=10, activation='relu',strides=5))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(filters=400, kernel_size=10, activation='relu',strides=5))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mean_absolute_error', optimizer= 'adam')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Adversarial_attack_')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8dab91cb55a779ebb65e73a37577434c9648b8bfd406d9f159bac9d9fb993402"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
