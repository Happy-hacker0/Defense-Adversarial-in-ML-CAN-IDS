{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\Adversarial_attack\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv1D,MaxPool1D\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "from joblib import dump, load\n",
    "import queue\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os, sys\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9700201207243461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97     22976\n",
      "           1       0.97      0.97      0.97     21754\n",
      "\n",
      "    accuracy                           0.97     44730\n",
      "   macro avg       0.97      0.97      0.97     44730\n",
      "weighted avg       0.97      0.97      0.97     44730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./Dataset/csv/Attack_merge.csv', newline='') as csvfile:\n",
    "        rows = pd.read_csv(csvfile,header=None)\n",
    "        y = rows[10]\n",
    "        x = rows.drop([10], axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y , test_size=0.2)\n",
    "    \n",
    "if not os.path.exists(\"./models\"):\n",
    "    os.mkdir(\"./models\")\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/DT.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\Speed_Lab\\Code\\Defense-Adversarial-in-ML-CAN-IDS\\train model.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39mscore(X_test, y_test))\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m dump(model, \u001b[39m'\u001b[39m\u001b[39m./models/RF.joblib\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=20, max_depth=4)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/RF.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9075788061703555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91     22799\n",
      "           1       0.90      0.91      0.91     21931\n",
      "\n",
      "    accuracy                           0.91     44730\n",
      "   macro avg       0.91      0.91      0.91     44730\n",
      "weighted avg       0.91      0.91      0.91     44730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=3)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/LR.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:10] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9765034652358596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98     22799\n",
      "           1       0.97      0.98      0.98     21931\n",
      "\n",
      "    accuracy                           0.98     44730\n",
      "   macro avg       0.98      0.98      0.98     44730\n",
      "weighted avg       0.98      0.98      0.98     44730\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(booster=\"gbtree\", min_split_loss=7.100747859845302e-07, alpha=0.0010277375135306342, \n",
    "                        max_depth=9, eta=0.6737504946980999, gamma=6.101266632438708e-07, grow_policy=\"lossguide\")\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/XGB.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9097250167672702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91     22799\n",
      "           1       0.91      0.91      0.91     21931\n",
      "\n",
      "    accuracy                           0.91     44730\n",
      "   macro avg       0.91      0.91      0.91     44730\n",
      "weighted avg       0.91      0.91      0.91     44730\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C = 2, verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/SVM.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9751844399731724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98     22799\n",
      "           1       0.97      0.98      0.97     21931\n",
      "\n",
      "    accuracy                           0.98     44730\n",
      "   macro avg       0.98      0.98      0.98     44730\n",
      "weighted avg       0.98      0.98      0.98     44730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/KNN.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/10\n",
      "4194/4194 [==============================] - 28s 6ms/step - loss: 0.2553 - accuracy: 0.8863 - val_loss: 0.1968 - val_accuracy: 0.9101\n",
      "Epoch 2/10\n",
      "4194/4194 [==============================] - 26s 6ms/step - loss: 0.2032 - accuracy: 0.9076 - val_loss: 0.1767 - val_accuracy: 0.9211\n",
      "Epoch 3/10\n",
      "4194/4194 [==============================] - 28s 7ms/step - loss: 0.1994 - accuracy: 0.9084 - val_loss: 0.1758 - val_accuracy: 0.9214\n",
      "Epoch 4/10\n",
      "4194/4194 [==============================] - 27s 6ms/step - loss: 0.1983 - accuracy: 0.9095 - val_loss: 0.1848 - val_accuracy: 0.9181\n",
      "Epoch 5/10\n",
      "4194/4194 [==============================] - 28s 7ms/step - loss: 0.1938 - accuracy: 0.9118 - val_loss: 0.1797 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/10\n",
      "4194/4194 [==============================] - 28s 7ms/step - loss: 0.1856 - accuracy: 0.9159 - val_loss: 0.1731 - val_accuracy: 0.9215\n",
      "Epoch 7/10\n",
      "4194/4194 [==============================] - 27s 6ms/step - loss: 0.1850 - accuracy: 0.9155 - val_loss: 0.1727 - val_accuracy: 0.9216\n",
      "Epoch 8/10\n",
      "4194/4194 [==============================] - 27s 6ms/step - loss: 0.1854 - accuracy: 0.9151 - val_loss: 0.1720 - val_accuracy: 0.9218\n",
      "Epoch 9/10\n",
      "4194/4194 [==============================] - 25s 6ms/step - loss: 0.1845 - accuracy: 0.9156 - val_loss: 0.1749 - val_accuracy: 0.9212\n",
      "Epoch 10/10\n",
      "4194/4194 [==============================] - 26s 6ms/step - loss: 0.1832 - accuracy: 0.9164 - val_loss: 0.1725 - val_accuracy: 0.9216\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('./models/DNN4_Best_Model.h5', save_weights_only=False, save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, epsilon=1e-4, mode='min')\n",
    "\n",
    "dnn4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(8, activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(4, activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "dnn4.compile(optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']);\n",
    "\n",
    "dnn4.fit(X_train, y_train, batch_size=batch_size, epochs=10, verbose=1, callbacks=[earlyStopping, mcp_save, reduce_lr_loss], validation_split=0.25)\n",
    "model = tf.keras.models.load_model('./models/DNN4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/DNN4.h5\")\n",
    "model = tf.keras.models.load_model('./models/DNN4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9208361278783814\n",
      "f1: 0.9181404165799755\n",
      "prec: 0.9277271665498715\n",
      "recall: 0.9087497711879919\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "pred_labels = np.rint(preds)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test, pred_labels[0:,1])\n",
    "f1 = sklearn.metrics.f1_score(y_test, pred_labels[0:,1], average=\"binary\")\n",
    "prec = sklearn.metrics.precision_score(y_test, pred_labels[0:,1], average=\"binary\")\n",
    "recall = sklearn.metrics.recall_score(y_test, pred_labels[0:,1], average=\"binary\")\n",
    "print(\"accuracy: \" + str(accuracy))\n",
    "print(\"f1: \" + str(f1))\n",
    "print(\"prec: \" + str(prec))\n",
    "print(\"recall: \" + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "y_train_ex = tf.expand_dims(y_train, axis=1)\n",
    "X_train_ex = tf.expand_dims(X_train, axis=2)\n",
    "y_test_ex = tf.expand_dims(y_test, axis=1)\n",
    "X_test_ex = tf.expand_dims(X_test, axis=2)\n",
    "y_train_ = np_utils.to_categorical(y_train)\n",
    "y_train_np = np.array(y_train_ex)\n",
    "X_train_np = np.array(X_train_ex)\n",
    "y_test_np = np.array(y_test_ex)\n",
    "X_test_np = np.array(X_test_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_111 (Conv1D)          (None, 10, 100)           600       \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 10, 200)           100200    \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 2, 400)            800400    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 1, 400)            0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 901,601\n",
      "Trainable params: 901,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1398/1398 [==============================] - 10s 7ms/step - loss: 0.2279 - accuracy: 0.9188\n",
      "Epoch 2/5\n",
      "1398/1398 [==============================] - 9s 6ms/step - loss: 0.1583 - accuracy: 0.9281\n",
      "Epoch 3/5\n",
      "1398/1398 [==============================] - 9s 6ms/step - loss: 0.1545 - accuracy: 0.9288\n",
      "Epoch 4/5\n",
      "1398/1398 [==============================] - 9s 6ms/step - loss: 0.1544 - accuracy: 0.9284\n",
      "Epoch 5/5\n",
      "1398/1398 [==============================] - 9s 6ms/step - loss: 0.1531 - accuracy: 0.9287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29fc3b50a60>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Embedding, GlobalAveragePooling1D\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=100, kernel_size=5, padding='same',activation='relu',strides=1, input_shape=(X_train_ex.shape[1],1))) \n",
    "model.add(Conv1D(filters=200, kernel_size=5, padding='same', activation='relu',strides=1))\n",
    "model.add(Conv1D(filters=400, kernel_size=10, padding='same', activation='relu',strides=5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train_ex, y_train_np, epochs=epochs, batch_size=batch_size,) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/CNN.h5\")\n",
    "model = tf.keras.models.load_model(\"./models/CNN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9282137268052761\n",
      "f1: 0.9251985929601416\n",
      "prec: 0.9422538552787663\n",
      "recall: 0.9087497711879919\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test_ex)\n",
    "pred_labels = np.rint(preds)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test_ex, pred_labels)\n",
    "f1 = sklearn.metrics.f1_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "prec = sklearn.metrics.precision_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "recall = sklearn.metrics.recall_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "print(\"accuracy: \" + str(accuracy))\n",
    "print(\"f1: \" + str(f1))\n",
    "print(\"prec: \" + str(prec))\n",
    "print(\"recall: \" + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train_np.shape[1], X_train_np.shape[2])))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5592/5592 [==============================] - 69s 11ms/step - loss: 0.3544 - accuracy: 0.9227\n",
      "Epoch 2/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.1407 - accuracy: 0.9546\n",
      "Epoch 3/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.1009 - accuracy: 0.9626\n",
      "Epoch 4/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0910 - accuracy: 0.9641\n",
      "Epoch 5/20\n",
      "5592/5592 [==============================] - 66s 12ms/step - loss: 0.0876 - accuracy: 0.9649\n",
      "Epoch 6/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0891 - accuracy: 0.9630\n",
      "Epoch 7/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0860 - accuracy: 0.9647\n",
      "Epoch 8/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0828 - accuracy: 0.9654\n",
      "Epoch 9/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0835 - accuracy: 0.9648\n",
      "Epoch 10/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0832 - accuracy: 0.9655\n",
      "Epoch 11/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0821 - accuracy: 0.9660\n",
      "Epoch 12/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0803 - accuracy: 0.9668\n",
      "Epoch 13/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0790 - accuracy: 0.9671\n",
      "Epoch 14/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0797 - accuracy: 0.9664\n",
      "Epoch 15/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0805 - accuracy: 0.9660\n",
      "Epoch 16/20\n",
      "5592/5592 [==============================] - 65s 12ms/step - loss: 0.0783 - accuracy: 0.9670\n",
      "Epoch 17/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0781 - accuracy: 0.9673\n",
      "Epoch 18/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0771 - accuracy: 0.9675\n",
      "Epoch 19/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0772 - accuracy: 0.9676\n",
      "Epoch 20/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0819 - accuracy: 0.9658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13116a50700>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "regressor.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "# 進行訓練\n",
    "regressor.fit(X_train_ex, y_train_ex, epochs = 20, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.save(\"./models/LSTM.h5\")\n",
    "model = tf.keras.models.load_model(\"./models/LSTM.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9692823608316566\n",
      "f1: 0.9683847215830649\n",
      "prec: 0.9694554501059615\n",
      "recall: 0.9673163556127609\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test_ex)\n",
    "pred_labels = np.rint(preds)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test_ex, pred_labels)\n",
    "f1 = sklearn.metrics.f1_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "prec = sklearn.metrics.precision_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "recall = sklearn.metrics.recall_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "print(\"accuracy: \" + str(accuracy))\n",
    "print(\"f1: \" + str(f1))\n",
    "print(\"prec: \" + str(prec))\n",
    "print(\"recall: \" + str(recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Adversarial_attack')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f6ad8de01885d29b1b3b20bb7ace6e41bbb669d38f4345665609eaa30831f6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
