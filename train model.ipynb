{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\Adversarial_attack\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv1D,MaxPool1D\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "from joblib import dump, load\n",
    "import queue\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os, sys\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Dataset/csv/Attack_merge.csv', newline='') as csvfile:\n",
    "        rows = pd.read_csv(csvfile,header=None)\n",
    "        y = rows[10]\n",
    "        x = rows.drop([10], axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y , test_size=0.2)\n",
    "    \n",
    "if not os.path.exists(\"./models\"):\n",
    "    os.mkdir(\"./models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9710932260228035\n",
      "[1. 1. 0. ... 1. 1. 1.]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97     22917\n",
      "           1       0.97      0.97      0.97     21813\n",
      "\n",
      "    accuracy                           0.97     44730\n",
      "   macro avg       0.97      0.97      0.97     44730\n",
      "weighted avg       0.97      0.97      0.97     44730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/DT.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "prediction_prob1 = model.predict_proba(X_test)\n",
    "print(prediction_prob1[0:,1])\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9485580147551979\n",
      "[0.91141263 0.99584606 0.26046839 ... 0.88290394 0.88290394 0.91141263]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     22917\n",
      "           1       0.99      0.91      0.95     21813\n",
      "\n",
      "    accuracy                           0.95     44730\n",
      "   macro avg       0.95      0.95      0.95     44730\n",
      "weighted avg       0.95      0.95      0.95     44730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=20, max_depth=4)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/RF.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "prediction_prob2 = model.predict_proba(X_test)\n",
    "print(prediction_prob2[0:,1])\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         0.         ... 1.         1.         1.        ]\n",
      " [0.91141263 0.99584606 0.26046839 ... 0.88290394 0.88290394 0.91141263]]\n",
      "[0.95570631 0.99792303 0.1302342  ... 0.94145197 0.94145197 0.95570631]\n",
      "[1. 1. 0. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([prediction_prob1[0:,1],prediction_prob2[0:,1]])\n",
    "print(a)\n",
    "a = np.average(a,axis=0)\n",
    "print(a)\n",
    "a = np.rint(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9075788061703555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91     22799\n",
      "           1       0.90      0.91      0.91     21931\n",
      "\n",
      "    accuracy                           0.91     44730\n",
      "   macro avg       0.91      0.91      0.91     44730\n",
      "weighted avg       0.91      0.91      0.91     44730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=3)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/LR.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\Adversarial_attack\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "e:\\anaconda\\envs\\Adversarial_attack\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:54:40] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9771294433266264\n",
      "[9.9997020e-01 2.0607738e-02 9.9999404e-01 ... 5.3720969e-06 9.9995923e-01\n",
      " 4.8870438e-06]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98     22922\n",
      "           1       0.97      0.98      0.98     21808\n",
      "\n",
      "    accuracy                           0.98     44730\n",
      "   macro avg       0.98      0.98      0.98     44730\n",
      "weighted avg       0.98      0.98      0.98     44730\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\Adversarial_attack\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(booster=\"gbtree\", min_split_loss=7.100747859845302e-07, alpha=0.0010277375135306342, \n",
    "                        max_depth=9, eta=0.6737504946980999, gamma=6.101266632438708e-07, grow_policy=\"lossguide\")\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/XGB.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.898859825620389\n",
      "[0.15382529 0.30297063 0.47198146 ... 0.14430225 0.47160139 0.63542526]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90     22831\n",
      "           1       0.89      0.91      0.90     21899\n",
      "\n",
      "    accuracy                           0.90     44730\n",
      "   macro avg       0.90      0.90      0.90     44730\n",
      "weighted avg       0.90      0.90      0.90     44730\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\Adversarial_attack\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C = 2, verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/SVM.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "prediction_prob = model._predict_proba_lr(X_test)\n",
    "print(prediction_prob[0:,1])\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9753856472166331\n",
      "[0 0 0 ... 1 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98     22652\n",
      "           1       0.97      0.98      0.98     22078\n",
      "\n",
      "    accuracy                           0.98     44730\n",
      "   macro avg       0.98      0.98      0.98     44730\n",
      "weighted avg       0.98      0.98      0.98     44730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/KNN.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(prediction)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Speed_Lab\\Code\\Defense-Adversarial-in-ML-CAN-IDS\\train model.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m dnn4 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mSequential([\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mInputLayer(input_shape\u001b[39m=\u001b[39m(X_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],)),\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mFlatten(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m2\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m ])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m dnn4\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]);\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m dnn4\u001b[39m.\u001b[39;49mfit(X_train, y_train, batch_size\u001b[39m=\u001b[39;49mbatch_size, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[earlyStopping, mcp_save, reduce_lr_loss], validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(\u001b[39m'\u001b[39m\u001b[39m./models/DNN4.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1177\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1178\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1179\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1180\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1181\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1182\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1183\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1184\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1185\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 889\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    891\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    892\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:950\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    947\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    949\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 950\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    951\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m   _, _, _, filtered_flat_args \u001b[39m=\u001b[39m \\\n\u001b[0;32m    953\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    954\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3021\u001b[0m   (graph_function,\n\u001b[0;32m   3022\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3024\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1956\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1958\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1959\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1961\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1962\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m     args,\n\u001b[0;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1965\u001b[0m     executing_eagerly)\n\u001b[0;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('./models/DNN4_Best_Model.h5', save_weights_only=False, save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, epsilon=1e-4, mode='min')\n",
    "\n",
    "dnn4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(8, activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(4, activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "dnn4.compile(optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']);\n",
    "\n",
    "dnn4.fit(X_train, y_train, batch_size=batch_size, epochs=10, verbose=1, callbacks=[earlyStopping, mcp_save, reduce_lr_loss], validation_split=0.25)\n",
    "model = tf.keras.models.load_model('./models/DNN4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"./models/DNN4.h5\")\n",
    "model = tf.keras.models.load_model('./models/DNN4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\Adversarial_attack\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:430: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.7736558e-01 4.2263442e-01]\n",
      " [1.4126042e-04 9.9985874e-01]\n",
      " [1.3915132e-02 9.8608482e-01]\n",
      " ...\n",
      " [9.9870741e-01 1.2926341e-03]\n",
      " [9.9930048e-01 6.9949619e-04]\n",
      " [9.9930012e-01 6.9987692e-04]]\n",
      "[4.2263442e-01 9.9985874e-01 9.8608482e-01 ... 1.2926341e-03 6.9949619e-04\n",
      " 6.9987692e-04]\n",
      "accuracy: 0.9213056114464565\n",
      "f1: 0.9185901290531479\n",
      "prec: 0.9301203690693645\n",
      "recall: 0.9073422579613469\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "pred_labels = np.rint(preds)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test, pred_labels[0:,1])\n",
    "f1 = sklearn.metrics.f1_score(y_test, pred_labels[0:,1], average=\"binary\")\n",
    "prec = sklearn.metrics.precision_score(y_test, pred_labels[0:,1], average=\"binary\")\n",
    "recall = sklearn.metrics.recall_score(y_test, pred_labels[0:,1], average=\"binary\")\n",
    "print(\"accuracy: \" + str(accuracy))\n",
    "print(\"f1: \" + str(f1))\n",
    "print(\"prec: \" + str(prec))\n",
    "print(\"recall: \" + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ex = tf.expand_dims(y_train, axis=1)\n",
    "X_train_ex = tf.expand_dims(X_train, axis=2)\n",
    "y_test_ex = tf.expand_dims(y_test, axis=1)\n",
    "X_test_ex = tf.expand_dims(X_test, axis=2)\n",
    "y_train_np = np.array(y_train_ex)\n",
    "X_train_np = np.array(X_train_ex)\n",
    "y_test_np = np.array(y_test_ex)\n",
    "X_test_np = np.array(X_test_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 10, 100)           600       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 10, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 10, 200)           100200    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 10, 400)           800400    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 5, 400)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 2001      \n",
      "=================================================================\n",
      "Total params: 903,201\n",
      "Trainable params: 903,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "699/699 [==============================] - 6s 8ms/step - loss: 0.3697 - accuracy: 0.8892\n",
      "Epoch 2/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1690 - accuracy: 0.9240\n",
      "Epoch 3/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1629 - accuracy: 0.9262\n",
      "Epoch 4/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1609 - accuracy: 0.9269\n",
      "Epoch 5/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1592 - accuracy: 0.9271\n",
      "Epoch 6/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1584 - accuracy: 0.9273\n",
      "Epoch 7/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1573 - accuracy: 0.9278\n",
      "Epoch 8/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1572 - accuracy: 0.9278\n",
      "Epoch 9/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1557 - accuracy: 0.9286\n",
      "Epoch 10/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1550 - accuracy: 0.9285\n",
      "Epoch 11/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1534 - accuracy: 0.9292\n",
      "Epoch 12/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1528 - accuracy: 0.9294\n",
      "Epoch 13/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1536 - accuracy: 0.9292\n",
      "Epoch 14/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1534 - accuracy: 0.9290\n",
      "Epoch 15/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1536 - accuracy: 0.9291\n",
      "Epoch 16/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1524 - accuracy: 0.9295\n",
      "Epoch 17/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1529 - accuracy: 0.9292\n",
      "Epoch 18/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1529 - accuracy: 0.9291\n",
      "Epoch 19/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1521 - accuracy: 0.9295\n",
      "Epoch 20/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1516 - accuracy: 0.9297\n",
      "Epoch 21/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1526 - accuracy: 0.9291\n",
      "Epoch 22/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1520 - accuracy: 0.9295\n",
      "Epoch 23/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1541 - accuracy: 0.9284\n",
      "Epoch 24/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1545 - accuracy: 0.9283\n",
      "Epoch 25/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1541 - accuracy: 0.9282\n",
      "Epoch 26/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1526 - accuracy: 0.9286\n",
      "Epoch 27/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1535 - accuracy: 0.9284\n",
      "Epoch 28/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1536 - accuracy: 0.9284\n",
      "Epoch 29/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1541 - accuracy: 0.9284\n",
      "Epoch 30/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1534 - accuracy: 0.9286\n",
      "Epoch 31/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1536 - accuracy: 0.9284\n",
      "Epoch 32/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1544 - accuracy: 0.9282\n",
      "Epoch 33/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1537 - accuracy: 0.9285\n",
      "Epoch 34/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1528 - accuracy: 0.9285\n",
      "Epoch 35/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1540 - accuracy: 0.9284\n",
      "Epoch 36/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1527 - accuracy: 0.9287\n",
      "Epoch 37/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1541 - accuracy: 0.9283\n",
      "Epoch 38/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1527 - accuracy: 0.9289\n",
      "Epoch 39/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1525 - accuracy: 0.9290\n",
      "Epoch 40/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1548 - accuracy: 0.9280\n",
      "Epoch 41/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1545 - accuracy: 0.9281\n",
      "Epoch 42/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1544 - accuracy: 0.9280\n",
      "Epoch 43/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1537 - accuracy: 0.9284\n",
      "Epoch 44/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1540 - accuracy: 0.9281\n",
      "Epoch 45/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1549 - accuracy: 0.9282\n",
      "Epoch 46/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1544 - accuracy: 0.9276\n",
      "Epoch 47/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1539 - accuracy: 0.9281\n",
      "Epoch 48/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1528 - accuracy: 0.9284\n",
      "Epoch 49/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1533 - accuracy: 0.9283\n",
      "Epoch 50/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1525 - accuracy: 0.9287\n",
      "Epoch 51/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1510 - accuracy: 0.9294\n",
      "Epoch 52/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1521 - accuracy: 0.9291\n",
      "Epoch 53/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1535 - accuracy: 0.9282\n",
      "Epoch 54/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1535 - accuracy: 0.9281\n",
      "Epoch 55/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1528 - accuracy: 0.9287\n",
      "Epoch 56/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1525 - accuracy: 0.9289\n",
      "Epoch 57/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1518 - accuracy: 0.9292\n",
      "Epoch 58/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1534 - accuracy: 0.9285\n",
      "Epoch 59/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1526 - accuracy: 0.9288\n",
      "Epoch 60/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1531 - accuracy: 0.9286\n",
      "Epoch 61/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1523 - accuracy: 0.9289\n",
      "Epoch 62/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1532 - accuracy: 0.9281\n",
      "Epoch 63/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1538 - accuracy: 0.9281\n",
      "Epoch 64/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1543 - accuracy: 0.9278\n",
      "Epoch 65/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1548 - accuracy: 0.9272\n",
      "Epoch 66/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1545 - accuracy: 0.9274\n",
      "Epoch 67/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1539 - accuracy: 0.9278\n",
      "Epoch 68/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1528 - accuracy: 0.9286\n",
      "Epoch 69/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1535 - accuracy: 0.9284\n",
      "Epoch 70/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1546 - accuracy: 0.9277\n",
      "Epoch 71/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1538 - accuracy: 0.9277\n",
      "Epoch 72/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1521 - accuracy: 0.9288\n",
      "Epoch 73/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1532 - accuracy: 0.9283\n",
      "Epoch 74/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1559 - accuracy: 0.9267\n",
      "Epoch 75/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1550 - accuracy: 0.9273\n",
      "Epoch 76/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1541 - accuracy: 0.9278\n",
      "Epoch 77/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1544 - accuracy: 0.9275\n",
      "Epoch 78/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1526 - accuracy: 0.9286\n",
      "Epoch 79/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1547 - accuracy: 0.9274\n",
      "Epoch 80/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1546 - accuracy: 0.9269\n",
      "Epoch 81/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1547 - accuracy: 0.9275\n",
      "Epoch 82/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1548 - accuracy: 0.9275\n",
      "Epoch 83/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1537 - accuracy: 0.9280\n",
      "Epoch 84/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1538 - accuracy: 0.9280\n",
      "Epoch 85/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1530 - accuracy: 0.9284\n",
      "Epoch 86/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1516 - accuracy: 0.9287\n",
      "Epoch 87/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1552 - accuracy: 0.9272\n",
      "Epoch 88/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1536 - accuracy: 0.9281\n",
      "Epoch 89/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1529 - accuracy: 0.9280\n",
      "Epoch 90/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1558 - accuracy: 0.9265\n",
      "Epoch 91/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1546 - accuracy: 0.9271\n",
      "Epoch 92/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1544 - accuracy: 0.9277\n",
      "Epoch 93/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1559 - accuracy: 0.9268\n",
      "Epoch 94/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1536 - accuracy: 0.9280\n",
      "Epoch 95/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1541 - accuracy: 0.9278\n",
      "Epoch 96/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1538 - accuracy: 0.9278\n",
      "Epoch 97/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1531 - accuracy: 0.9283\n",
      "Epoch 98/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1539 - accuracy: 0.9280\n",
      "Epoch 99/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1530 - accuracy: 0.9280\n",
      "Epoch 100/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1532 - accuracy: 0.9281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26cb4bf9070>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Embedding, GlobalAveragePooling1D\n",
    "epochs = 100\n",
    "batch_size = 256\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=100, kernel_size=5, padding='same',activation='relu',strides=1, input_shape=(X_train_ex.shape[1],1))) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=200, kernel_size=5, padding='same', activation='relu',strides=1))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=400, kernel_size=10, padding='same', activation='relu',strides=1))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train_ex, y_train_np, epochs=epochs, batch_size=batch_size,) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"./models/CNN.h5\")\n",
    "model = tf.keras.models.load_model(\"./models/CNN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9300022356360385\n",
      "f1: 0.9269294499288199\n",
      "prec: 0.9473809750977961\n",
      "recall: 0.9073422579613469\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test_ex)\n",
    "pred_labels = np.rint(preds)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test_ex, pred_labels)\n",
    "f1 = sklearn.metrics.f1_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "prec = sklearn.metrics.precision_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "recall = sklearn.metrics.recall_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "print(\"accuracy: \" + str(accuracy))\n",
    "print(\"f1: \" + str(f1))\n",
    "print(\"prec: \" + str(prec))\n",
    "print(\"recall: \" + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 10, 50)            10400     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10, 50)            20200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10, 50)            20200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 71,051\n",
      "Trainable params: 71,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train_np.shape[1], X_train_np.shape[2])))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(1, activation='sigmoid'))\n",
    "regressor.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5592/5592 [==============================] - 69s 11ms/step - loss: 0.3544 - accuracy: 0.9227\n",
      "Epoch 2/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.1407 - accuracy: 0.9546\n",
      "Epoch 3/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.1009 - accuracy: 0.9626\n",
      "Epoch 4/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0910 - accuracy: 0.9641\n",
      "Epoch 5/20\n",
      "5592/5592 [==============================] - 66s 12ms/step - loss: 0.0876 - accuracy: 0.9649\n",
      "Epoch 6/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0891 - accuracy: 0.9630\n",
      "Epoch 7/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0860 - accuracy: 0.9647\n",
      "Epoch 8/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0828 - accuracy: 0.9654\n",
      "Epoch 9/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0835 - accuracy: 0.9648\n",
      "Epoch 10/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0832 - accuracy: 0.9655\n",
      "Epoch 11/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0821 - accuracy: 0.9660\n",
      "Epoch 12/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0803 - accuracy: 0.9668\n",
      "Epoch 13/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0790 - accuracy: 0.9671\n",
      "Epoch 14/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0797 - accuracy: 0.9664\n",
      "Epoch 15/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0805 - accuracy: 0.9660\n",
      "Epoch 16/20\n",
      "5592/5592 [==============================] - 65s 12ms/step - loss: 0.0783 - accuracy: 0.9670\n",
      "Epoch 17/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0781 - accuracy: 0.9673\n",
      "Epoch 18/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0771 - accuracy: 0.9675\n",
      "Epoch 19/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0772 - accuracy: 0.9676\n",
      "Epoch 20/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0819 - accuracy: 0.9658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13116a50700>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 進行訓練\n",
    "regressor.fit(X_train_ex, y_train_ex, epochs = 20, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regressor.save(\"./models/LSTM.h5\")\n",
    "model = tf.keras.models.load_model(\"./models/LSTM.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\Adversarial_attack\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:430: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.5782835e-01]\n",
      " [9.9833703e-01]\n",
      " [9.9833858e-01]\n",
      " ...\n",
      " [8.8761508e-04]\n",
      " [8.9969923e-04]\n",
      " [8.9435477e-04]]\n",
      "accuracy: 0.9684328191370445\n",
      "f1: 0.9676606660253767\n",
      "prec: 0.9701492537313433\n",
      "recall: 0.9651848129026362\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test_ex)\n",
    "print(model.predict_proba(X_test_ex))\n",
    "pred_labels = np.rint(preds)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test_ex, pred_labels)\n",
    "f1 = sklearn.metrics.f1_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "prec = sklearn.metrics.precision_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "recall = sklearn.metrics.recall_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "print(\"accuracy: \" + str(accuracy))\n",
    "print(\"f1: \" + str(f1))\n",
    "print(\"prec: \" + str(prec))\n",
    "print(\"recall: \" + str(recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Adversarial_attack')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f6ad8de01885d29b1b3b20bb7ace6e41bbb669d38f4345665609eaa30831f6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
