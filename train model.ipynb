{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv1D,MaxPool1D\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "from joblib import dump, load\n",
    "import queue\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os, sys\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Dataset/csv/Attack_merge.csv', newline='') as csvfile:\n",
    "        rows = pd.read_csv(csvfile,header=None)\n",
    "        y = rows[10]\n",
    "        x = rows.drop([10], axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y , test_size=0.2)\n",
    "    \n",
    "if not os.path.exists(\"./models\"):\n",
    "    os.mkdir(\"./models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/DT.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\Speed_Lab\\Code\\Defense-Adversarial-in-ML-CAN-IDS\\train model.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, max_depth\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39mscore(X_test, y_test))\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m dump(model, \u001b[39m'\u001b[39m\u001b[39m./models/RF.joblib\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=20, max_depth=4)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/RF.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9075788061703555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91     22799\n",
      "           1       0.90      0.91      0.91     21931\n",
      "\n",
      "    accuracy                           0.91     44730\n",
      "   macro avg       0.91      0.91      0.91     44730\n",
      "weighted avg       0.91      0.91      0.91     44730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=3)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/LR.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:10] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9765034652358596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98     22799\n",
      "           1       0.97      0.98      0.98     21931\n",
      "\n",
      "    accuracy                           0.98     44730\n",
      "   macro avg       0.98      0.98      0.98     44730\n",
      "weighted avg       0.98      0.98      0.98     44730\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(booster=\"gbtree\", min_split_loss=7.100747859845302e-07, alpha=0.0010277375135306342, \n",
    "                        max_depth=9, eta=0.6737504946980999, gamma=6.101266632438708e-07, grow_policy=\"lossguide\")\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/XGB.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9097250167672702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91     22799\n",
      "           1       0.91      0.91      0.91     21931\n",
      "\n",
      "    accuracy                           0.91     44730\n",
      "   macro avg       0.91      0.91      0.91     44730\n",
      "weighted avg       0.91      0.91      0.91     44730\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C = 2, verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/SVM.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9753856472166331\n",
      "[0 0 0 ... 1 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98     22652\n",
      "           1       0.97      0.98      0.98     22078\n",
      "\n",
      "    accuracy                           0.98     44730\n",
      "   macro avg       0.98      0.98      0.98     44730\n",
      "weighted avg       0.98      0.98      0.98     44730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/KNN.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(prediction)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/10\n",
      "4194/4194 [==============================] - 28s 6ms/step - loss: 0.2553 - accuracy: 0.8863 - val_loss: 0.1968 - val_accuracy: 0.9101\n",
      "Epoch 2/10\n",
      "4194/4194 [==============================] - 26s 6ms/step - loss: 0.2032 - accuracy: 0.9076 - val_loss: 0.1767 - val_accuracy: 0.9211\n",
      "Epoch 3/10\n",
      "4194/4194 [==============================] - 28s 7ms/step - loss: 0.1994 - accuracy: 0.9084 - val_loss: 0.1758 - val_accuracy: 0.9214\n",
      "Epoch 4/10\n",
      "4194/4194 [==============================] - 27s 6ms/step - loss: 0.1983 - accuracy: 0.9095 - val_loss: 0.1848 - val_accuracy: 0.9181\n",
      "Epoch 5/10\n",
      "4194/4194 [==============================] - 28s 7ms/step - loss: 0.1938 - accuracy: 0.9118 - val_loss: 0.1797 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/10\n",
      "4194/4194 [==============================] - 28s 7ms/step - loss: 0.1856 - accuracy: 0.9159 - val_loss: 0.1731 - val_accuracy: 0.9215\n",
      "Epoch 7/10\n",
      "4194/4194 [==============================] - 27s 6ms/step - loss: 0.1850 - accuracy: 0.9155 - val_loss: 0.1727 - val_accuracy: 0.9216\n",
      "Epoch 8/10\n",
      "4194/4194 [==============================] - 27s 6ms/step - loss: 0.1854 - accuracy: 0.9151 - val_loss: 0.1720 - val_accuracy: 0.9218\n",
      "Epoch 9/10\n",
      "4194/4194 [==============================] - 25s 6ms/step - loss: 0.1845 - accuracy: 0.9156 - val_loss: 0.1749 - val_accuracy: 0.9212\n",
      "Epoch 10/10\n",
      "4194/4194 [==============================] - 26s 6ms/step - loss: 0.1832 - accuracy: 0.9164 - val_loss: 0.1725 - val_accuracy: 0.9216\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('./models/DNN4_Best_Model.h5', save_weights_only=False, save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, epsilon=1e-4, mode='min')\n",
    "\n",
    "dnn4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(8, activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(4, activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "dnn4.compile(optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']);\n",
    "\n",
    "dnn4.fit(X_train, y_train, batch_size=batch_size, epochs=10, verbose=1, callbacks=[earlyStopping, mcp_save, reduce_lr_loss], validation_split=0.25)\n",
    "model = tf.keras.models.load_model('./models/DNN4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Lab\\Code\\Defense Adversarial in ML CAN IDS\\train model.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Lab/Code/Defense%20Adversarial%20in%20ML%20CAN%20IDS/train%20model.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39m./models/DNN4.h5\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Lab/Code/Defense%20Adversarial%20in%20ML%20CAN%20IDS/train%20model.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(\u001b[39m'\u001b[39m\u001b[39m./models/DNN4.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(\"./models/DNN4.h5\")\n",
    "model = tf.keras.models.load_model('./models/DNN4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9208361278783814\n",
      "f1: 0.9181404165799755\n",
      "prec: 0.9277271665498715\n",
      "recall: 0.9087497711879919\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "pred_labels = np.rint(preds)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test, pred_labels[0:,1])\n",
    "f1 = sklearn.metrics.f1_score(y_test, pred_labels[0:,1], average=\"binary\")\n",
    "prec = sklearn.metrics.precision_score(y_test, pred_labels[0:,1], average=\"binary\")\n",
    "recall = sklearn.metrics.recall_score(y_test, pred_labels[0:,1], average=\"binary\")\n",
    "print(\"accuracy: \" + str(accuracy))\n",
    "print(\"f1: \" + str(f1))\n",
    "print(\"prec: \" + str(prec))\n",
    "print(\"recall: \" + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ex = tf.expand_dims(y_train, axis=1)\n",
    "X_train_ex = tf.expand_dims(X_train, axis=2)\n",
    "y_test_ex = tf.expand_dims(y_test, axis=1)\n",
    "X_test_ex = tf.expand_dims(X_test, axis=2)\n",
    "y_train_np = np.array(y_train_ex)\n",
    "X_train_np = np.array(X_train_ex)\n",
    "y_test_np = np.array(y_test_ex)\n",
    "X_test_np = np.array(X_test_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 10, 100)           600       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 10, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 10, 200)           100200    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 10, 200)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 10, 400)           800400    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 5, 400)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 2001      \n",
      "=================================================================\n",
      "Total params: 903,201\n",
      "Trainable params: 903,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "699/699 [==============================] - 6s 8ms/step - loss: 0.3697 - accuracy: 0.8892\n",
      "Epoch 2/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1690 - accuracy: 0.9240\n",
      "Epoch 3/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1629 - accuracy: 0.9262\n",
      "Epoch 4/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1609 - accuracy: 0.9269\n",
      "Epoch 5/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1592 - accuracy: 0.9271\n",
      "Epoch 6/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1584 - accuracy: 0.9273\n",
      "Epoch 7/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1573 - accuracy: 0.9278\n",
      "Epoch 8/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1572 - accuracy: 0.9278\n",
      "Epoch 9/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1557 - accuracy: 0.9286\n",
      "Epoch 10/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1550 - accuracy: 0.9285\n",
      "Epoch 11/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1534 - accuracy: 0.9292\n",
      "Epoch 12/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1528 - accuracy: 0.9294\n",
      "Epoch 13/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1536 - accuracy: 0.9292\n",
      "Epoch 14/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1534 - accuracy: 0.9290\n",
      "Epoch 15/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1536 - accuracy: 0.9291\n",
      "Epoch 16/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1524 - accuracy: 0.9295\n",
      "Epoch 17/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1529 - accuracy: 0.9292\n",
      "Epoch 18/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1529 - accuracy: 0.9291\n",
      "Epoch 19/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1521 - accuracy: 0.9295\n",
      "Epoch 20/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1516 - accuracy: 0.9297\n",
      "Epoch 21/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1526 - accuracy: 0.9291\n",
      "Epoch 22/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1520 - accuracy: 0.9295\n",
      "Epoch 23/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1541 - accuracy: 0.9284\n",
      "Epoch 24/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1545 - accuracy: 0.9283\n",
      "Epoch 25/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1541 - accuracy: 0.9282\n",
      "Epoch 26/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1526 - accuracy: 0.9286\n",
      "Epoch 27/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1535 - accuracy: 0.9284\n",
      "Epoch 28/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1536 - accuracy: 0.9284\n",
      "Epoch 29/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1541 - accuracy: 0.9284\n",
      "Epoch 30/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1534 - accuracy: 0.9286\n",
      "Epoch 31/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1536 - accuracy: 0.9284\n",
      "Epoch 32/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1544 - accuracy: 0.9282\n",
      "Epoch 33/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1537 - accuracy: 0.9285\n",
      "Epoch 34/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1528 - accuracy: 0.9285\n",
      "Epoch 35/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1540 - accuracy: 0.9284\n",
      "Epoch 36/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1527 - accuracy: 0.9287\n",
      "Epoch 37/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1541 - accuracy: 0.9283\n",
      "Epoch 38/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1527 - accuracy: 0.9289\n",
      "Epoch 39/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1525 - accuracy: 0.9290\n",
      "Epoch 40/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1548 - accuracy: 0.9280\n",
      "Epoch 41/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1545 - accuracy: 0.9281\n",
      "Epoch 42/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1544 - accuracy: 0.9280\n",
      "Epoch 43/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1537 - accuracy: 0.9284\n",
      "Epoch 44/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1540 - accuracy: 0.9281\n",
      "Epoch 45/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1549 - accuracy: 0.9282\n",
      "Epoch 46/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1544 - accuracy: 0.9276\n",
      "Epoch 47/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1539 - accuracy: 0.9281\n",
      "Epoch 48/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1528 - accuracy: 0.9284\n",
      "Epoch 49/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1533 - accuracy: 0.9283\n",
      "Epoch 50/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1525 - accuracy: 0.9287\n",
      "Epoch 51/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1510 - accuracy: 0.9294\n",
      "Epoch 52/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1521 - accuracy: 0.9291\n",
      "Epoch 53/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1535 - accuracy: 0.9282\n",
      "Epoch 54/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1535 - accuracy: 0.9281\n",
      "Epoch 55/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1528 - accuracy: 0.9287\n",
      "Epoch 56/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1525 - accuracy: 0.9289\n",
      "Epoch 57/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1518 - accuracy: 0.9292\n",
      "Epoch 58/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1534 - accuracy: 0.9285\n",
      "Epoch 59/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1526 - accuracy: 0.9288\n",
      "Epoch 60/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1531 - accuracy: 0.9286\n",
      "Epoch 61/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1523 - accuracy: 0.9289\n",
      "Epoch 62/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1532 - accuracy: 0.9281\n",
      "Epoch 63/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1538 - accuracy: 0.9281\n",
      "Epoch 64/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1543 - accuracy: 0.9278\n",
      "Epoch 65/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1548 - accuracy: 0.9272\n",
      "Epoch 66/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1545 - accuracy: 0.9274\n",
      "Epoch 67/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1539 - accuracy: 0.9278\n",
      "Epoch 68/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1528 - accuracy: 0.9286\n",
      "Epoch 69/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1535 - accuracy: 0.9284\n",
      "Epoch 70/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1546 - accuracy: 0.9277\n",
      "Epoch 71/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1538 - accuracy: 0.9277\n",
      "Epoch 72/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1521 - accuracy: 0.9288\n",
      "Epoch 73/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1532 - accuracy: 0.9283\n",
      "Epoch 74/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1559 - accuracy: 0.9267\n",
      "Epoch 75/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1550 - accuracy: 0.9273\n",
      "Epoch 76/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1541 - accuracy: 0.9278\n",
      "Epoch 77/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1544 - accuracy: 0.9275\n",
      "Epoch 78/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1526 - accuracy: 0.9286\n",
      "Epoch 79/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1547 - accuracy: 0.9274\n",
      "Epoch 80/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1546 - accuracy: 0.9269\n",
      "Epoch 81/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1547 - accuracy: 0.9275\n",
      "Epoch 82/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1548 - accuracy: 0.9275\n",
      "Epoch 83/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1537 - accuracy: 0.9280\n",
      "Epoch 84/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1538 - accuracy: 0.9280\n",
      "Epoch 85/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1530 - accuracy: 0.9284\n",
      "Epoch 86/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1516 - accuracy: 0.9287\n",
      "Epoch 87/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1552 - accuracy: 0.9272\n",
      "Epoch 88/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1536 - accuracy: 0.9281\n",
      "Epoch 89/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1529 - accuracy: 0.9280\n",
      "Epoch 90/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1558 - accuracy: 0.9265\n",
      "Epoch 91/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1546 - accuracy: 0.9271\n",
      "Epoch 92/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1544 - accuracy: 0.9277\n",
      "Epoch 93/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1559 - accuracy: 0.9268\n",
      "Epoch 94/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1536 - accuracy: 0.9280\n",
      "Epoch 95/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1541 - accuracy: 0.9278\n",
      "Epoch 96/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1538 - accuracy: 0.9278\n",
      "Epoch 97/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1531 - accuracy: 0.9283\n",
      "Epoch 98/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1539 - accuracy: 0.9280\n",
      "Epoch 99/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1530 - accuracy: 0.9280\n",
      "Epoch 100/100\n",
      "699/699 [==============================] - 5s 7ms/step - loss: 0.1532 - accuracy: 0.9281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26cb4bf9070>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Embedding, GlobalAveragePooling1D\n",
    "epochs = 100\n",
    "batch_size = 256\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=100, kernel_size=5, padding='same',activation='relu',strides=1, input_shape=(X_train_ex.shape[1],1))) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=200, kernel_size=5, padding='same', activation='relu',strides=1))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=400, kernel_size=10, padding='same', activation='relu',strides=1))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train_ex, y_train_np, epochs=epochs, batch_size=batch_size,) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"./models/CNN.h5\")\n",
    "model = tf.keras.models.load_model(\"./models/CNN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9314106863402638\n",
      "f1: 0.9291585850189341\n",
      "prec: 0.9477154969382948\n",
      "recall: 0.9113144306549507\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test_ex)\n",
    "pred_labels = np.rint(preds)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test_ex, pred_labels)\n",
    "f1 = sklearn.metrics.f1_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "prec = sklearn.metrics.precision_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "recall = sklearn.metrics.recall_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "print(\"accuracy: \" + str(accuracy))\n",
    "print(\"f1: \" + str(f1))\n",
    "print(\"prec: \" + str(prec))\n",
    "print(\"recall: \" + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 10, 50)            10400     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10, 50)            20200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10, 50)            20200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 71,051\n",
      "Trainable params: 71,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train_np.shape[1], X_train_np.shape[2])))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "regressor.add(Dense(1, activation='sigmoid'))\n",
    "regressor.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5592/5592 [==============================] - 69s 11ms/step - loss: 0.3544 - accuracy: 0.9227\n",
      "Epoch 2/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.1407 - accuracy: 0.9546\n",
      "Epoch 3/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.1009 - accuracy: 0.9626\n",
      "Epoch 4/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0910 - accuracy: 0.9641\n",
      "Epoch 5/20\n",
      "5592/5592 [==============================] - 66s 12ms/step - loss: 0.0876 - accuracy: 0.9649\n",
      "Epoch 6/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0891 - accuracy: 0.9630\n",
      "Epoch 7/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0860 - accuracy: 0.9647\n",
      "Epoch 8/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0828 - accuracy: 0.9654\n",
      "Epoch 9/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0835 - accuracy: 0.9648\n",
      "Epoch 10/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0832 - accuracy: 0.9655\n",
      "Epoch 11/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0821 - accuracy: 0.9660\n",
      "Epoch 12/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0803 - accuracy: 0.9668\n",
      "Epoch 13/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0790 - accuracy: 0.9671\n",
      "Epoch 14/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0797 - accuracy: 0.9664\n",
      "Epoch 15/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0805 - accuracy: 0.9660\n",
      "Epoch 16/20\n",
      "5592/5592 [==============================] - 65s 12ms/step - loss: 0.0783 - accuracy: 0.9670\n",
      "Epoch 17/20\n",
      "5592/5592 [==============================] - 64s 11ms/step - loss: 0.0781 - accuracy: 0.9673\n",
      "Epoch 18/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0771 - accuracy: 0.9675\n",
      "Epoch 19/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0772 - accuracy: 0.9676\n",
      "Epoch 20/20\n",
      "5592/5592 [==============================] - 63s 11ms/step - loss: 0.0819 - accuracy: 0.9658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13116a50700>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 進行訓練\n",
    "regressor.fit(X_train_ex, y_train_ex, epochs = 20, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.save(\"./models/LSTM.h5\")\n",
    "model = tf.keras.models.load_model(\"./models/LSTM.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9692823608316566\n",
      "f1: 0.9683847215830649\n",
      "prec: 0.9694554501059615\n",
      "recall: 0.9673163556127609\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test_ex)\n",
    "pred_labels = np.rint(preds)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test_ex, pred_labels)\n",
    "f1 = sklearn.metrics.f1_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "prec = sklearn.metrics.precision_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "recall = sklearn.metrics.recall_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "print(\"accuracy: \" + str(accuracy))\n",
    "print(\"f1: \" + str(f1))\n",
    "print(\"prec: \" + str(prec))\n",
    "print(\"recall: \" + str(recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Adversarial_attack_')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8dab91cb55a779ebb65e73a37577434c9648b8bfd406d9f159bac9d9fb993402"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
