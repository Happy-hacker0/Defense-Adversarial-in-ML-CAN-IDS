{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv1D,MaxPool1D\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "from joblib import dump, load\n",
    "import queue\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os, sys\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9686116700201207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97     22878\n",
      "           1       0.97      0.96      0.97     21852\n",
      "\n",
      "    accuracy                           0.97     44730\n",
      "   macro avg       0.97      0.97      0.97     44730\n",
      "weighted avg       0.97      0.97      0.97     44730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./Dataset/csv/Attack_merge.csv', newline='') as csvfile:\n",
    "        rows = pd.read_csv(csvfile,header=None)\n",
    "        y = rows[10]\n",
    "        x = rows.drop([10], axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y , test_size=0.2)\n",
    "    \n",
    "if not os.path.exists(\"./models\"):\n",
    "    os.mkdir(\"./models\")\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/DT.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948647440196736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95     22799\n",
      "           1       0.99      0.91      0.95     21931\n",
      "\n",
      "    accuracy                           0.95     44730\n",
      "   macro avg       0.95      0.95      0.95     44730\n",
      "weighted avg       0.95      0.95      0.95     44730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=20, max_depth=4)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/RF.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9075788061703555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91     22799\n",
      "           1       0.90      0.91      0.91     21931\n",
      "\n",
      "    accuracy                           0.91     44730\n",
      "   macro avg       0.91      0.91      0.91     44730\n",
      "weighted avg       0.91      0.91      0.91     44730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=3)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/LR.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:10] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9765034652358596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98     22799\n",
      "           1       0.97      0.98      0.98     21931\n",
      "\n",
      "    accuracy                           0.98     44730\n",
      "   macro avg       0.98      0.98      0.98     44730\n",
      "weighted avg       0.98      0.98      0.98     44730\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(booster=\"gbtree\", min_split_loss=7.100747859845302e-07, alpha=0.0010277375135306342, \n",
    "                        max_depth=9, eta=0.6737504946980999, gamma=6.101266632438708e-07, grow_policy=\"lossguide\")\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/XGB.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9097250167672702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91     22799\n",
      "           1       0.91      0.91      0.91     21931\n",
      "\n",
      "    accuracy                           0.91     44730\n",
      "   macro avg       0.91      0.91      0.91     44730\n",
      "weighted avg       0.91      0.91      0.91     44730\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LinearSVC(C = 2, verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/SVM.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9751844399731724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98     22799\n",
      "           1       0.97      0.98      0.97     21931\n",
      "\n",
      "    accuracy                           0.98     44730\n",
      "   macro avg       0.98      0.98      0.98     44730\n",
      "weighted avg       0.98      0.98      0.98     44730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))\n",
    "dump(model, './models/KNN.joblib')\n",
    "prediction = model.predict(X_test)\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "Epoch 1/10\n",
      "4194/4194 [==============================] - 28s 6ms/step - loss: 0.2553 - accuracy: 0.8863 - val_loss: 0.1968 - val_accuracy: 0.9101\n",
      "Epoch 2/10\n",
      "4194/4194 [==============================] - 26s 6ms/step - loss: 0.2032 - accuracy: 0.9076 - val_loss: 0.1767 - val_accuracy: 0.9211\n",
      "Epoch 3/10\n",
      "4194/4194 [==============================] - 28s 7ms/step - loss: 0.1994 - accuracy: 0.9084 - val_loss: 0.1758 - val_accuracy: 0.9214\n",
      "Epoch 4/10\n",
      "4194/4194 [==============================] - 27s 6ms/step - loss: 0.1983 - accuracy: 0.9095 - val_loss: 0.1848 - val_accuracy: 0.9181\n",
      "Epoch 5/10\n",
      "4194/4194 [==============================] - 28s 7ms/step - loss: 0.1938 - accuracy: 0.9118 - val_loss: 0.1797 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 6/10\n",
      "4194/4194 [==============================] - 28s 7ms/step - loss: 0.1856 - accuracy: 0.9159 - val_loss: 0.1731 - val_accuracy: 0.9215\n",
      "Epoch 7/10\n",
      "4194/4194 [==============================] - 27s 6ms/step - loss: 0.1850 - accuracy: 0.9155 - val_loss: 0.1727 - val_accuracy: 0.9216\n",
      "Epoch 8/10\n",
      "4194/4194 [==============================] - 27s 6ms/step - loss: 0.1854 - accuracy: 0.9151 - val_loss: 0.1720 - val_accuracy: 0.9218\n",
      "Epoch 9/10\n",
      "4194/4194 [==============================] - 25s 6ms/step - loss: 0.1845 - accuracy: 0.9156 - val_loss: 0.1749 - val_accuracy: 0.9212\n",
      "Epoch 10/10\n",
      "4194/4194 [==============================] - 26s 6ms/step - loss: 0.1832 - accuracy: 0.9164 - val_loss: 0.1725 - val_accuracy: 0.9216\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('./models/DNN4_Best_Model.h5', save_weights_only=False, save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, epsilon=1e-4, mode='min')\n",
    "\n",
    "dnn4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(8, activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(4, activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.01),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "dnn4.compile(optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']);\n",
    "\n",
    "dnn4.fit(X_train, y_train, batch_size=batch_size, epochs=10, verbose=1, callbacks=[earlyStopping, mcp_save, reduce_lr_loss], validation_split=0.25)\n",
    "model = tf.keras.models.load_model('./models/DNN4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/DNN4.h5\")\n",
    "model = tf.keras.models.load_model('./models/DNN4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9208361278783814\n",
      "f1: 0.9181404165799755\n",
      "prec: 0.9277271665498715\n",
      "recall: 0.9087497711879919\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "pred_labels = np.rint(preds)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test, pred_labels[0:,1])\n",
    "f1 = sklearn.metrics.f1_score(y_test, pred_labels[0:,1], average=\"binary\")\n",
    "prec = sklearn.metrics.precision_score(y_test, pred_labels[0:,1], average=\"binary\")\n",
    "recall = sklearn.metrics.recall_score(y_test, pred_labels[0:,1], average=\"binary\")\n",
    "print(\"accuracy: \" + str(accuracy))\n",
    "print(\"f1: \" + str(f1))\n",
    "print(\"prec: \" + str(prec))\n",
    "print(\"recall: \" + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178919, 10, 1)\n",
      "(178919, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_np = np.array(X_train).reshape(-1, 10, 1)\n",
    "print(X_train_np.shape)\n",
    "y_train_np = np.array(y_train).reshape(y_train.shape[0], 1)\n",
    "print(y_train_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "y_train_ex = tf.expand_dims(y_train, axis=1)\n",
    "X_train_ex = tf.expand_dims(X_train, axis=2)\n",
    "y_test_ex = tf.expand_dims(y_test, axis=1)\n",
    "X_test_ex = tf.expand_dims(X_test, axis=2)\n",
    "y_train_ = np_utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import float32\n",
    "\n",
    "y_train_np = np.array(y_train_ex)\n",
    "X_train_np = np.array(X_train_ex)\n",
    "y_test_np = np.array(y_test_ex)\n",
    "X_test_np = np.array(X_test_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 10, 100)           200       \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 10, 60)            6060      \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 10, 80)            4880      \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 10, 160)           12960     \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 10, 160)           25760     \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 10, 160)           0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 10, 1)             161       \n",
      "=================================================================\n",
      "Total params: 50,021\n",
      "Trainable params: 50,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1398/1398 [==============================] - 9s 6ms/step - loss: 0.6705\n",
      "Epoch 2/10\n",
      "1398/1398 [==============================] - 8s 6ms/step - loss: 0.6543\n",
      "Epoch 3/10\n",
      "1398/1398 [==============================] - 8s 6ms/step - loss: 0.6414\n",
      "Epoch 4/10\n",
      " 654/1398 [=============>................] - ETA: 4s - loss: 0.6254"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Speed_Lab\\Code\\Defense-Adversarial-in-ML-CAN-IDS\\train model.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39msummary()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#X20sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train_ex, y_train_ex, epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size,)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1177\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1178\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1179\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1180\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1181\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1182\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1183\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1184\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1185\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 889\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    891\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    892\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3021\u001b[0m   (graph_function,\n\u001b[0;32m   3022\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3024\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1956\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1958\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1959\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1961\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1962\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m     args,\n\u001b[0;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1965\u001b[0m     executing_eagerly)\n\u001b[0;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#OK\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Conv1D, MaxPooling1D, InputLayer, Embedding, GlobalAveragePooling1D\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(10, 1)))\n",
    "model.add(Conv1D(filters=60, kernel_size=5, activation='relu', strides=1)) \n",
    "# model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(filters=80, kernel_size, activation='relu', strides=1))\n",
    "#model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(filters=160, kernel_size=1, activation='relu'))\n",
    "model.add(Conv1D(filters=160, kernel_size=1, activation='relu'))\n",
    "#model.add(GlobalAveragePooling1D())\n",
    "#model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer= 'adam')\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train_ex, y_train_ex, epochs=epochs, batch_size=batch_size,) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_111 (Conv1D)          (None, 10, 100)           600       \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 10, 200)           100200    \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 2, 400)            800400    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 1, 400)            0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 901,601\n",
      "Trainable params: 901,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1398/1398 [==============================] - 10s 7ms/step - loss: 0.2279 - accuracy: 0.9188\n",
      "Epoch 2/5\n",
      "1398/1398 [==============================] - 9s 6ms/step - loss: 0.1583 - accuracy: 0.9281\n",
      "Epoch 3/5\n",
      "1398/1398 [==============================] - 9s 6ms/step - loss: 0.1545 - accuracy: 0.9288\n",
      "Epoch 4/5\n",
      "1398/1398 [==============================] - 9s 6ms/step - loss: 0.1544 - accuracy: 0.9284\n",
      "Epoch 5/5\n",
      "1398/1398 [==============================] - 9s 6ms/step - loss: 0.1531 - accuracy: 0.9287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29fc3b50a60>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Embedding, GlobalAveragePooling1D\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=100, kernel_size=5, padding='same',activation='relu',strides=1, input_shape=(X_train_ex.shape[1],1))) \n",
    "model.add(Conv1D(filters=200, kernel_size=5, padding='same', activation='relu',strides=1))\n",
    "model.add(Conv1D(filters=400, kernel_size=10, padding='same', activation='relu',strides=5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train_ex, y_train_np, epochs=epochs, batch_size=batch_size,) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/CNN.h5\")\n",
    "model.load(\"./models/CNN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9282137268052761\n",
      "f1: 0.9251985929601416\n",
      "prec: 0.9422538552787663\n",
      "recall: 0.9087497711879919\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test_ex)\n",
    "pred_labels = np.rint(preds)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test_ex, pred_labels)\n",
    "f1 = sklearn.metrics.f1_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "prec = sklearn.metrics.precision_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "recall = sklearn.metrics.recall_score(y_test_ex, pred_labels, average=\"binary\")\n",
    "print(\"accuracy: \" + str(accuracy))\n",
    "print(\"f1: \" + str(f1))\n",
    "print(\"prec: \" + str(prec))\n",
    "print(\"recall: \" + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic Tensor (lstm_3/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32me:\\Speed_Lab\\Code\\Defense-Adversarial-in-ML-CAN-IDS\\train model.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m regressor \u001b[39m=\u001b[39m Sequential()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m regressor\u001b[39m.\u001b[39;49madd(LSTM(units \u001b[39m=\u001b[39;49m \u001b[39m50\u001b[39;49m, return_sequences \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, input_shape \u001b[39m=\u001b[39;49m (X_train_np\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], X_train_np\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m])))\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m regressor\u001b[39m.\u001b[39madd(Dropout(\u001b[39m0.2\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Speed_Lab/Code/Defense-Adversarial-in-ML-CAN-IDS/train%20model.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Adding a second LSTM layer and some Dropout regularisation\u001b[39;00m\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:522\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    521\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 522\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    523\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    524\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:213\u001b[0m, in \u001b[0;36mSequential.add\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    208\u001b[0m     x \u001b[39m=\u001b[39m input_layer\u001b[39m.\u001b[39mInput(\n\u001b[0;32m    209\u001b[0m         batch_shape\u001b[39m=\u001b[39mbatch_shape, dtype\u001b[39m=\u001b[39mdtype, name\u001b[39m=\u001b[39mlayer\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_input\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    210\u001b[0m     \u001b[39m# This will build the current layer\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[39m# and create the node connecting the current layer\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[39m# to the input layer we just created.\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m     layer(x)\n\u001b[0;32m    214\u001b[0m     set_inputs \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \u001b[39mif\u001b[39;00m set_inputs:\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:668\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    662\u001b[0m inputs, initial_state, constants \u001b[39m=\u001b[39m _standardize_args(inputs,\n\u001b[0;32m    663\u001b[0m                                                      initial_state,\n\u001b[0;32m    664\u001b[0m                                                      constants,\n\u001b[0;32m    665\u001b[0m                                                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_constants)\n\u001b[0;32m    667\u001b[0m \u001b[39mif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m constants \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 668\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(RNN, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    670\u001b[0m \u001b[39m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[0;32m    671\u001b[0m \u001b[39m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[0;32m    672\u001b[0m \u001b[39m# input_spec to include them.\u001b[39;00m\n\u001b[0;32m    674\u001b[0m additional_inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:969\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[0;32m    964\u001b[0m \u001b[39m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[0;32m    965\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[0;32m    966\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\u001b[39mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[1;32m--> 969\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m    970\u001b[0m                                             input_list)\n\u001b[0;32m    972\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[0;32m    973\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1107\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     training_arg_passed_by_framework \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m \u001b[39mwith\u001b[39;00m call_context\u001b[39m.\u001b[39menter(\n\u001b[0;32m   1105\u001b[0m     layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39minputs, build_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39mtraining_value):\n\u001b[0;32m   1106\u001b[0m   \u001b[39m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[1;32m-> 1107\u001b[0m   outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keras_tensor_symbolic_call(\n\u001b[0;32m   1108\u001b[0m       inputs, input_masks, args, kwargs)\n\u001b[0;32m   1110\u001b[0m   \u001b[39mif\u001b[39;00m outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1111\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mA layer\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39ms `call` method should return a \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1112\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mTensor or a list of Tensors, not None \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1113\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m(layer: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m).\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:840\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    838\u001b[0m   \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39mmap_structure(keras_tensor\u001b[39m.\u001b[39mKerasTensor, output_signature)\n\u001b[0;32m    839\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 840\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:880\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    878\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_build(inputs)\n\u001b[0;32m    879\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[1;32m--> 880\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    882\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[0;32m    883\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks,\n\u001b[0;32m    884\u001b[0m                         build_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py:1153\u001b[0m, in \u001b[0;36mLSTM.call\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_args_if_ragged(is_ragged_input, mask)\n\u001b[0;32m   1152\u001b[0m \u001b[39m# LSTM does not support constants. Ignore it during process.\u001b[39;00m\n\u001b[1;32m-> 1153\u001b[0m inputs, initial_state, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_inputs(inputs, initial_state, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(mask, \u001b[39mlist\u001b[39m):\n\u001b[0;32m   1156\u001b[0m   mask \u001b[39m=\u001b[39m mask[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:868\u001b[0m, in \u001b[0;36mRNN._process_inputs\u001b[1;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[0;32m    866\u001b[0m     initial_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstates\n\u001b[0;32m    867\u001b[0m \u001b[39melif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 868\u001b[0m   initial_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_initial_state(inputs)\n\u001b[0;32m    870\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(initial_state) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstates):\n\u001b[0;32m    871\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mLayer has \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstates)) \u001b[39m+\u001b[39m\n\u001b[0;32m    872\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m states but was passed \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(initial_state)) \u001b[39m+\u001b[39m\n\u001b[0;32m    873\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m initial states.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:650\u001b[0m, in \u001b[0;36mRNN.get_initial_state\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    648\u001b[0m dtype \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mdtype\n\u001b[0;32m    649\u001b[0m \u001b[39mif\u001b[39;00m get_initial_state_fn:\n\u001b[1;32m--> 650\u001b[0m   init_state \u001b[39m=\u001b[39m get_initial_state_fn(\n\u001b[0;32m    651\u001b[0m       inputs\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, batch_size\u001b[39m=\u001b[39;49mbatch_size, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    652\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    653\u001b[0m   init_state \u001b[39m=\u001b[39m _generate_zero_filled_state(batch_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcell\u001b[39m.\u001b[39mstate_size,\n\u001b[0;32m    654\u001b[0m                                            dtype)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:2516\u001b[0m, in \u001b[0;36mLSTMCell.get_initial_state\u001b[1;34m(self, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2515\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_initial_state\u001b[39m(\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, batch_size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 2516\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_generate_zero_filled_state_for_cell(\n\u001b[0;32m   2517\u001b[0m       \u001b[39mself\u001b[39;49m, inputs, batch_size, dtype))\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:2998\u001b[0m, in \u001b[0;36m_generate_zero_filled_state_for_cell\u001b[1;34m(cell, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2996\u001b[0m   batch_size \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39mshape(inputs)[\u001b[39m0\u001b[39m]\n\u001b[0;32m   2997\u001b[0m   dtype \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mdtype\n\u001b[1;32m-> 2998\u001b[0m \u001b[39mreturn\u001b[39;00m _generate_zero_filled_state(batch_size, cell\u001b[39m.\u001b[39;49mstate_size, dtype)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:3014\u001b[0m, in \u001b[0;36m_generate_zero_filled_state\u001b[1;34m(batch_size_tensor, state_size, dtype)\u001b[0m\n\u001b[0;32m   3011\u001b[0m   \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39mzeros(init_state_size, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m   3013\u001b[0m \u001b[39mif\u001b[39;00m nest\u001b[39m.\u001b[39mis_nested(state_size):\n\u001b[1;32m-> 3014\u001b[0m   \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39;49mmap_structure(create_zeros, state_size)\n\u001b[0;32m   3015\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3016\u001b[0m   \u001b[39mreturn\u001b[39;00m create_zeros(state_size)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:867\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    863\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    864\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    866\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 867\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    868\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:867\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    863\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    864\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    866\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 867\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    868\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:3011\u001b[0m, in \u001b[0;36m_generate_zero_filled_state.<locals>.create_zeros\u001b[1;34m(unnested_state_size)\u001b[0m\n\u001b[0;32m   3009\u001b[0m flat_dims \u001b[39m=\u001b[39m tensor_shape\u001b[39m.\u001b[39mTensorShape(unnested_state_size)\u001b[39m.\u001b[39mas_list()\n\u001b[0;32m   3010\u001b[0m init_state_size \u001b[39m=\u001b[39m [batch_size_tensor] \u001b[39m+\u001b[39m flat_dims\n\u001b[1;32m-> 3011\u001b[0m \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39;49mzeros(init_state_size, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2911\u001b[0m, in \u001b[0;36m_tag_zeros_tensor.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2910\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2911\u001b[0m   tensor \u001b[39m=\u001b[39m fun(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   2912\u001b[0m   tensor\u001b[39m.\u001b[39m_is_zeros_tensor \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   2913\u001b[0m   \u001b[39mreturn\u001b[39;00m tensor\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2960\u001b[0m, in \u001b[0;36mzeros\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m   2956\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2957\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m   2958\u001b[0m     \u001b[39m# Create a constant if it won't be very big. Otherwise create a fill\u001b[39;00m\n\u001b[0;32m   2959\u001b[0m     \u001b[39m# op to prevent serialized GraphDefs from becoming too large.\u001b[39;00m\n\u001b[1;32m-> 2960\u001b[0m     output \u001b[39m=\u001b[39m _constant_if_small(zero, shape, dtype, name)\n\u001b[0;32m   2961\u001b[0m     \u001b[39mif\u001b[39;00m output \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2962\u001b[0m       \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2896\u001b[0m, in \u001b[0;36m_constant_if_small\u001b[1;34m(value, shape, dtype, name)\u001b[0m\n\u001b[0;32m   2894\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_if_small\u001b[39m(value, shape, dtype, name):\n\u001b[0;32m   2895\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2896\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39;49mprod(shape) \u001b[39m<\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[0;32m   2897\u001b[0m       \u001b[39mreturn\u001b[39;00m constant(value, shape\u001b[39m=\u001b[39mshape, dtype\u001b[39m=\u001b[39mdtype, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m   2898\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   2899\u001b[0m     \u001b[39m# Happens when shape is a Tensor, list with Tensor elements, etc.\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mprod\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3051\u001b[0m, in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2933\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_prod_dispatcher)\n\u001b[0;32m   2934\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprod\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[0;32m   2935\u001b[0m          initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[0;32m   2936\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2937\u001b[0m \u001b[39m    Return the product of array elements over a given axis.\u001b[39;00m\n\u001b[0;32m   2938\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3049\u001b[0m \u001b[39m    10\u001b[39;00m\n\u001b[0;32m   3050\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3051\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mmultiply, \u001b[39m'\u001b[39;49m\u001b[39mprod\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out,\n\u001b[0;32m   3052\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "File \u001b[1;32me:\\anaconda\\envs\\Adversarial_attack_\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:867\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 867\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    868\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mCannot convert a symbolic Tensor (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) to a numpy array.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    869\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m This error may indicate that you\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre trying to pass a Tensor to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    870\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m a NumPy call, which is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname))\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (lstm_3/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported"
     ]
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train_np.shape[1], X_train_np.shape[2])))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Adversarial_attack_')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61f29a1603a8932024fdf9d65a54616726f56a29b1ceec9534994072fe61c2ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
