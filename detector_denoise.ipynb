{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import newaxis\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.5.0\n",
      "tensorflow version: 2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(f\"tensorflow version: {tf.__version__}\")\n",
    "print(f\"tensorflow version: {tf.keras.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import normal Dataset\n",
    "def import_dataset(filename = \"./Dataset/csv/Attacked/Original_X_test.csv\"):\n",
    "    with open(filename, newline='') as csvfile:\n",
    "        rows = pd.read_csv(csvfile,header=None)\n",
    "        X_train, X_test = train_test_split(rows, test_size=0.2)\n",
    "        X_train = np.array(X_train)\n",
    "        X_test = np.array(X_test)\n",
    "        X_train_ex = X_train[:, newaxis]\n",
    "        X_test_ex = X_test[:, :, newaxis]\n",
    "    return X_train, X_test, X_train_ex, X_test_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = import_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "latent_space (Dense)         (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 10)                90        \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 440\n",
      "Trainable params: 440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "input_img = tf.keras.layers.Input(shape = (X_train.shape[1],))\n",
    "encoder = tf.keras.layers.Dense(10, activation='relu')(input_img)\n",
    "encoder = tf.keras.layers.Dense(8, activation='relu')(encoder)\n",
    "encoder = tf.keras.layers.Dense(2, activation='relu', name=\"latent_space\")(encoder)\n",
    "\n",
    "decoder = tf.keras.layers.Dense(8, activation='relu')(encoder)\n",
    "decoder = tf.keras.layers.Dense(10, activation='relu')(decoder)\n",
    "decoder = tf.keras.layers.Dense(X_train.shape[1], activation='softmax')(decoder)\n",
    "\n",
    "autoencoder = tf.keras.models.Model(input_img, decoder)\n",
    "autoencoder.compile(loss='binary_crossentropy', optimizer= 'adam')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "140/140 [==============================] - 1s 4ms/step - loss: -13.2453 - val_loss: -36.0155\n",
      "Epoch 2/10\n",
      "140/140 [==============================] - 0s 3ms/step - loss: -85.6157 - val_loss: -153.7113\n",
      "Epoch 3/10\n",
      "140/140 [==============================] - 0s 3ms/step - loss: -271.8967 - val_loss: -417.2727\n",
      "Epoch 4/10\n",
      "140/140 [==============================] - 0s 3ms/step - loss: -634.9857 - val_loss: -884.8526\n",
      "Epoch 5/10\n",
      "140/140 [==============================] - 0s 3ms/step - loss: -1229.6410 - val_loss: -1606.3561\n",
      "Epoch 6/10\n",
      "140/140 [==============================] - 0s 3ms/step - loss: -2102.0671 - val_loss: -2623.7695\n",
      "Epoch 7/10\n",
      "140/140 [==============================] - 0s 3ms/step - loss: -3291.8240 - val_loss: -3974.5588\n",
      "Epoch 8/10\n",
      "140/140 [==============================] - 0s 3ms/step - loss: -4832.2710 - val_loss: -5689.4482\n",
      "Epoch 9/10\n",
      "140/140 [==============================] - 1s 4ms/step - loss: -6751.4341 - val_loss: -7790.8706\n",
      "Epoch 10/10\n",
      "140/140 [==============================] - 1s 4ms/step - loss: -9075.0693 - val_loss: -10301.3516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13a77bc1dc0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_train ,X_train ,epochs=10, batch_size=256,validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_msg = autoencoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000000e+00, 1.0987715e-01, 5.8243882e-10, 8.9012164e-01,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.0672850e-13,\n",
       "       1.2030154e-06, 0.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_msg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous-multioutput and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Lab\\Code\\Defense Adversarial in ML CAN IDS\\detector_denoise.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Lab/Code/Defense%20Adversarial%20in%20ML%20CAN%20IDS/detector_denoise.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m preds \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Lab/Code/Defense%20Adversarial%20in%20ML%20CAN%20IDS/detector_denoise.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pred_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrint(preds)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Lab/Code/Defense%20Adversarial%20in%20ML%20CAN%20IDS/detector_denoise.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m accuracy \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39;49mmetrics\u001b[39m.\u001b[39;49maccuracy_score(X_test, pred_labels[\u001b[39m0\u001b[39;49m:,\u001b[39m1\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\sklearn\\metrics\\_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    213\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Maxwang\\anaconda3\\envs\\Adversarial_attack_\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and binary targets"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "preds = autoencoder.predict(X_test)\n",
    "pred_labels = np.rint(preds)\n",
    "accuracy = sklearn.metrics.accuracy_score(X_test, pred_labels[0:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Embedding, GlobalAveragePooling1D\n",
    "epochs = 100\n",
    "batch_size = 256\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=100, kernel_size=5, padding='same',activation='relu',strides=1, input_shape=(X_train_ex.shape[1],1))) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=200, kernel_size=5, padding='same', activation='relu',strides=1))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=400, kernel_size=10, padding='same', activation='relu',strides=1))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Adversarial_attack_')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8dab91cb55a779ebb65e73a37577434c9648b8bfd406d9f159bac9d9fb993402"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
